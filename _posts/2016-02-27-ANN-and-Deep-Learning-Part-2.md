---
layout: post
title:  "ANN and Deep Learning Part 2"
date: 2016-02-27 09:02:26 +0800
categories: "algorithm"
author: xxiieao
---

人工神经网络（ANN，Artificial Neural Network）是个非常大的话题，我将按照我自己的理解从讲解其中关键的几个点这个概念讲清楚。

### 神经网络的结构

讨论人工神经网络之前，先来说一说它所模仿的生物对象。人工神经网络所模仿的是动物神经网络，而神经系统基本单位则是神经元。翻开许多生物学教材，我们可以发现神经元大概长成下面这个样子。细胞体伸出来短的叫树突，长的叫轴突。其中树突负责接受信号并且转导到细胞内，而轴突则负责将信号传递出去。由此看来，一个神经元可以接受其它神经元传递过来的信号，并且自己加以处理后再传下一个神经元。

![picture](http://ww3.sinaimg.cn/mw690/6daafd01gw1f1f2qbfkaoj20lm0dqjt5.jpg)

一个典型的人工神经网络也是如此，网络中节点（node）就像一个个细胞体，而节点之间的连接就相当于细胞上突起。输入的数据通过连接传递到节点，经节点进行处理后再向下传递，如此一层层向下传递直到输出结果的一层。连接上的数字被称为权重，权重代表这个连接的强弱。人工神经网络的学习实际上就是调整节点之间的连接权重，通过调整这些连接的强弱，我们则可以使得同一个输入的会出现不同的处理结果。

![picture](http://ww1.sinaimg.cn/mw690/6daafd01gw1f1f2su4hp5j20bv09cmy5.jpg)

### 多层感知器

最常见的一种人工神经网络是一种叫做**多层感知器(multilayer perceptron)**的**前馈(feed-forward neural network)神经网络**。**前馈**是指神经网络中的每一层节点都从上一层接受数据（信号），处理后传给下一层。而这个**感知器**就比较有意思了，名字有点让人云里雾里的。实际上节点中对数据进行处理的函数，通常被称为激活函数（activation function）。感知器指的就是激活函数的名称，函数如下

$$
f(x) =
\begin{cases}
+1, & x\ge{0} \\
-1, & x<0
\end{cases}
$$

正如在他的《Pattern Recognition and Machine Learning》一书中提到的，多层感知器这个名字具有误导性，因为在多层感知器中真正广泛使用的激活函数实际上是逻辑斯蒂方程（logistic function or sigmoid function）。

### 逻辑斯蒂方程

逻辑斯蒂方程是连续的非线性方程，函数如下

$$f(x) = \dfrac{1}{1+e^{-x}}$$

函数图像如下

![picture](http://ww4.sinaimg.cn/mw690/6daafd01gw1f1f3v8r1nbj20dc0dcq31.jpg)

它的一些优秀的性质导致其相比感知器方程更适合作为激活函数。可以注意到，逻辑斯蒂方程在中间有一段迅速变化的曲线，这段曲线使得使用梯度下降法（gradient descent）来调整参数时，可以使得结果快速地向两边（即0和1）靠拢，这一点是感知器方程比较难做到的。

### 反向传播

最后一个技术细节是关于人工神经网络是如何学习的，训练人工神经网络的算法叫做反向转播算法（error backpropagation）。这算法实际上相当简单，就是将误差从输出层开始，通过节点间的连接反向传播回去。

### 关于人工神经网络的思考

通过各种资料我们可以从各种途径知道神经网络的各种技术细节，但是作为一种可以用于机器学习的算法而言，从本质上来说它是如何完成分类分析的呢？我很同意一位做微博上一位自然语言分析专家的说法，即分类算法从本质上来说只有升维和降维两种做法。比如PCA显然是降维技术，而SVM则是升维技术。而人工神经网络又是怎样呢？就多层感知器这个例子来说，我觉得人工神经网络本质上是升维的，通过增加隐含层的节点来制造一些原来的数据集中可能不存在的维度。在这一点上我认为，这正是多层感知器与深度学习最不同的地方，深度学习通过自动编码这一过程来实现特征的提取，因此本质上是去掉原数据集中多余与不重要的数据，而这是典型降维处理方法。
